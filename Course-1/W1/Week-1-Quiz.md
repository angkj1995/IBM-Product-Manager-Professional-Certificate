**1.** Product management typically discover and evaluate a customer’s need by:
- [x] Through relentless research and study of customer needs.
- [ ] Employee suggestions.
- [ ] Customers contact the company and provide requirements. 
- [ ] A single focus group meeting.

**2.** How does a lack of product management strategy impact a company? 
- [ ] It forces the company to take a project management approach. 
- [x] It limits their ability to place a product strategically. 
- [ ] Merge with other companies to produce products by volume.
- [ ] Nothing, Product Management is an optional exercise. 

**3.** A successful product manager should have which of the following abilities?
- [ ] Having detailed insight into how their competitor’s intellectual property
- [ ] Using instinct to develop a product
- [x] Knowing a little bit about each functional area that supports the effort
- [ ] Having a firm grasp on executive decision making

**4.** Which of the following stages are part of the generative AI model lifecycle mentioned in the course? (Select all that apply)
- [x] Deploying the model into the infrastructure and integrating it with the application.
- [x] Defining the problem and identifying relevant datasets.
- [ ] Performing regularization
- [x] Manipulating the model to align with specific project needs.
- [x] Selecting a candidate model and potentially pre-training a custom model.

**5.** "RNNs are better than Transformers for generative AI Tasks."

Is this true or false?
- [ ] True
- [x] False

**6.** Which transformer-based model architecture has the objective of guessing a masked token based on the previous sequence of tokens by building bidirectional representations of the input sequence.
- [x] Autoencoder
- [ ] Autoregressive
- [ ] Sequence-to-sequence

**7.** Which transformer-based model architecture is well-suited to the task of text translation?
- [ ] Autoencoder
- [ ] Autoregressive
- [x] Sequence-to-sequence

**8.** Do we always need to increase the model size to improve its performance?
- [ ] True
- [x] False

**9.** Scaling laws for pre-training large language models consider several aspects to maximize performance of a model within a set of constraints and available scaling choices. Select all alternatives that should be considered for scaling when performing model pre-training?
- [ ]Batch size: Number of samples per iteration 
- [x] Model size: Number of parameters
- [x] Dataset size: Number of tokens
- [x] Compute budget: Compute constraints

**10.** "You can combine data parallelism with model parallelism to train LLMs."

Is this true or false?
- [x] True
- [ ] False
